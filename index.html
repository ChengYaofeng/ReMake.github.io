<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>ReMake</title>
    <!-- Bootstrap -->
    <link rel="preconnect" href="https://rsms.me/">
    <link rel="stylesheet" href="https://rsms.me/inter/inter.css">
    <link href="css/bootstrap-4.4.1.css" rel="stylesheet">
    <link href="css/main.css" rel="stylesheet">

    <!-- MathJax Script -->
    <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>

    <style>
      body {
        background: rgb(255, 255, 255) no-repeat fixed top left; 
        font-family: "Inter", 'Open Sans', sans-serif;
      }
    </style>

  </head>

  <!-- cover -->
  <section>
    <div class="jumbotron text-center mt-0">
      <div class="container-fluid">
        <div class="row">
          <div class="col">
            <h2 style="font-size:30px;">Rethinking Transparent Object Grasping:</h2> 
            <h2 style="font-size:30px;">Depth Completion with Monocular Depth Estimation and Instance Mask</h2>
            <!-- <h4 style="color:#6e6e6e;">  </h4> -->
            <hr>
            <h6>
              Yaofeng Cheng<sup>1,2,3</sup>&nbsp; &nbsp;
              Xinkai Gao<sup>1,2</sup>&nbsp; &nbsp;
              Sen Zhang<sup>1,2</sup>&nbsp; &nbsp;
              Chao Zeng<sup>3</sup>&nbsp; &nbsp;
              Fusheng Zha<sup>1,2†</sup>&nbsp; &nbsp;
              Lining Sun<sup>1</sup>&nbsp; &nbsp;
              Chenguang Yang<sup>3†</sup>&nbsp; &nbsp;
              <br>
              <br>
            <p>
              <sup>1</sup>Harbin Institute of Technology&nbsp; &nbsp;
              <sup>2</sup>State Key Laboratory of Robotics and System&nbsp; &nbsp;
              <sup>3</sup>University of Liverpool&nbsp; &nbsp;
              <br>
            </p>
            <p> <sup>†</sup> corresponding author &nbsp;
              <br>
          </p>

            <div class="row justify-content-center">
              <div class="column">
                  <p class="mb-5">
                    <a class="btn btn-large btn-light" href="https://arxiv.org/abs/2508.02507" role="button" target="_blank">
                    <!-- <a class="btn btn-large btn-light" href="https://arxiv.org/abs/2211.05272" role="button" target="_blank"> -->
                    <i class="fa fa-file"></i> Paper </a> </p>
              </div>
              <div class="column">
                  <p class="mb-5"><a class="btn btn-large btn-light" href="" role="button" target="_blank">
                  <!-- <p class="mb-5"><a class="btn btn-large btn-light" href="https://github.com/PKU-EPIC/GAPartNet" role="button" target="_blank"> -->
                <i class="fa fa-github-alt"></i> Code </a> </p>
              </div>
            </div>

          </div>
        </div>
      </div>
    </div>
  </section>

  <!-- teaser -->
  <section>
    <div class="container">
      <div class="row">
        <div class="col-12 text-center">
            <hr style="margin-top:0px">
              <div class="row justify-content-center" style="align-items:center; display:flex;">
               <img src="images/fig1.png" alt="input" class="img-responsive graph" width="95%"/>
              <br>
            </div>
            <p class="text-justify">
	      We propose <b>ReMake</b>, <b>Re</b>lative depth and <b>Ma</b>s<b>k</b> att<b>e</b>ntion guided depth completion.
        We predict a complete depth map from a single RGB-D image, enabling accurate target object points extraction 
        and 6-DoF grasp prediction.
            </p>
        </div>
      </div>
    </div>
  </section>
  <br>

  <!-- abstract -->
  <section>
    <div class="container">
      <div class="row">
        <div class="col-12">
          <h2><strong>Abstract</strong></h2>
            <hr style="margin-top:0px">
            <p class="text-justify">
              Transparent objects are common in daily life. 
              Unlike opaque objects, light emitted from depth cameras is often refracted or reflected on transparent surfaces, 
              resulting in missing or erroneous depth values. 
              Only regions where reflected light returns to the camera yield valid depth values. 
              The mixture of missing, incorrect, and valid depth introduces significant noise, 
              hindering accurate perception and reliable grasping. 
              However, most existing methods only feed RGB-D image into the network, 
              requiring the model to implicitly distinguish between reliable and unreliable depth. While effective on training datasets, 
              these methods struggle to generalize to real-world scenes due to the highly variable distribution of valid and invalid depth caused by complex light interactions. 
              This motivates us to rethink the efficiency of current training strategies. 
              To address this, we propose ReMake, a novel depth completion framework guided by instance mask and relative depth. 
              The mask explicitly distinguishes regions from non-transparent ones, 
              enabling the model to focus on learning to predict accurate depth in transparent areas from RGB-D input during its training process. 
              This targeted supervision reduces reliance on implicit reasoning and improves generalization to real-world scenarios. 
              Additionally, the relative depth map encodes spatial relationships between the transparent object and its surroundings, 
              enhancing prediction accuracy. 
              Extensive experiments show that our method outperforms existing approaches on both benchmark datasets and real-world scenarios, 
              demonstrating superior accuracy and generalization capability.
          </p>
        </div>
      </div>
    </div>
  </section>
  <br>

  <!-- Methods -->
  <section>
    <div class="container">
      <div class="row">
        <div class="col-12">
          <h2><strong>Methods</strong></h2>
            <hr style="margin-top:0px">
            <h3 style="margin-top:20px; margin-bottom:20px; color:#717980"><b>Full pipeline</b></h3>
              <div class="row justify-content-center" style="align-items:center; display:flex;">
                <img src="images/fig3.png" alt="input" class="img-responsive graph" width="95%"/>
              </div>
              <p class="text-justify">
                <b>The instance mask and relative depth map are generated via segmentation and monocular depth estimation. 
                  The RGB image concatenated with the mask is encoded using a Transformer. 
                  The relative depth and original depth are separately encoded, 
                  and all features are fused and decoded to predict the complete depth map. 
                  The target object's point cloud is then extracted using the instance mask.
              </p>
            <br>
        </div>
        </div>
      </div>
    </div>
  </section>
  <br>
  <br>

    <!-- Results -->
    <section>
      <div class="container">
        <div class="row">
          <div class="col-12">
            <h2><strong>Results</strong></h2>
              <hr style="margin-top:0px">
                <!-- <h3 style="margin-top:20px; margin-bottom:20px; color:#717980"><b>Cross-Category Part Segmentation</b></h3>  -->
                We show the quatitative comparisons on the TransCG dataset.
                <p class="text-justify">
                  <div class="row justify-content-center" style="align-items:center; display:flex;">
                    <img src="images/datasetresults.png" alt="input" class="img-responsive graph" width="95%"/>
                  </div>
                </p>
                We visualize a qualitative comparisons between our method and the State-of-the-Art methods on the TransCG dataset. 
                Although ground truth have some noise points, our method remain robust.
                <p class="text-justify">
                  <div class="row justify-content-center" style="align-items:center; display:flex;">
                    <img src="images/fig4.png" alt="input" class="img-responsive graph" width="95%"/>
                  </div>
                </p>
                 We tested our method in real-world experiments. 
                 To evaluate generalization more effectively, we varied the objects, backgrounds, and viewpoints during testing, 
                 noting that viewpoint changes also alter background depth.
                <p class="text-justify">
                  <div class="row justify-content-center" style="align-items:center; display:flex;">
                    <img src="images/fig6.png" alt="input" class="img-responsive graph" width="95%"/>
                  </div>
                </p>
                <p class="text-justify">
                  <h3 style="margin-top:20px; margin-bottom:20px; color:#717980"><b>Top-down View</b></h3>
                  <div class="row justify-content-center" style="align-items:center; display:flex;">
                    <img src="images/td1.gif" alt="input" class="img-responsive graph" width="95%"/>
                  </div>
                  <div class="row justify-content-center" style="align-items:center; display:flex;">
                    <img src="images/td2.gif" alt="input" class="img-responsive graph" width="95%"/>
                  </div>
                  <div class="row justify-content-center" style="align-items:center; display:flex;">
                    <img src="images/td3.gif" alt="input" class="img-responsive graph" width="95%"/>
                  </div>
                  <div class="row justify-content-center" style="align-items:center; display:flex;">
                    <img src="images/td4.gif" alt="input" class="img-responsive graph" width="95%"/>
                  </div>
                  <div class="row justify-content-center" style="align-items:center; display:flex;">
                    <img src="images/td5.gif" alt="input" class="img-responsive graph" width="95%"/>
                  </div>
                </p>
                <p class="text-justify">
                  <h3 style="margin-top:20px; margin-bottom:20px; color:#717980"><b>Bird-eye View</b></h3>
                  <div class="row justify-content-center" style="align-items:center; display:flex;">
                    <img src="images/be1.gif" alt="input" class="img-responsive graph" width="95%"/>
                  </div>
                  <div class="row justify-content-center" style="align-items:center; display:flex;">
                    <img src="images/be2.gif" alt="input" class="img-responsive graph" width="95%"/>
                  </div>
                  <div class="row justify-content-center" style="align-items:center; display:flex;">
                    <img src="images/be3.gif" alt="input" class="img-responsive graph" width="95%"/>
                  </div>
                </p>
                <p class="text-justify">
                  <h3 style="margin-top:20px; margin-bottom:20px; color:#717980"><b>Horizontal View</b></h3>
                  <div class="row justify-content-center" style="align-items:center; display:flex;">
                    <img src="images/h1.gif" alt="input" class="img-responsive graph" width="95%"/>
                  </div>
                  <div class="row justify-content-center" style="align-items:center; display:flex;">
                    <img src="images/h2.gif" alt="input" class="img-responsive graph" width="95%"/>
                  </div>
                  <div class="row justify-content-center" style="align-items:center; display:flex;">
                    <img src="images/h3.gif" alt="input" class="img-responsive graph" width="95%"/>
                  </div>
                </p>
                <p class="text-justify">
                  <h3 style="margin-top:20px; margin-bottom:20px; color:#717980"><b>Application Demo & Extreme Scenario</b></h3>
                  <div class="row justify-content-center" style="align-items:center; display:flex;">
                    <img src="images/demo.gif" alt="input" class="img-responsive graph" width="95%"/>
                  </div>
                </p>
  
          </div>
          </div>
        </div>
      </div>
    </section>
    <br>

  <!-- citing -->
  <div class="container">
    <div class="row ">
      <div class="col-12">
          <h2><strong>Citation</strong></h2>
          <hr style="margin-top:0px">
              <!-- <pre style="background-color: #e9eeef;padding: 1.25em 1.5em"> -->
<pre style="background-color: #e9eeef;padding: 0 1.5em">
<code>
@article{cheng2025rethinkingtransparentobjectgrasping,
      title={Rethinking Transparent Object Grasping: Depth Completion with Monocular Depth Estimation and Instance Mask}, 
      author={Yaofeng Cheng and Xinkai Gao and Sen Zhang and Chao Zeng and Fusheng Zha and Lining Sun and Chenguang Yang},
      year={2025},
      eprint={2508.02507},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2508.02507},
}
</code>
</pre>
      </div>
    </div>
  </div>
  <br>

    <!-- Contact -->
    <div class="container">
      <div class="row ">
        <div class="col-12">
            <h2><strong>Contact</strong></h2>
            <hr style="margin-top:0px">
            <p>If you have any questions, please feel free to contact us:
              <ul>
                <li><b>Yaofeng Cheng</b>&colon; chengyf<span style="display:none">Prevent spamming</span>@<span style="display:none">Prevent spamming</span>stu.hit.edu.cn </li>
              </ul>
            </p>
        </pre>
        </div>
      </div>
    </div>

</body>
</html>
